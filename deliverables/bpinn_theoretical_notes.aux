\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Why PINNs are Inherently Robust to High-Frequency Noise}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Data: Boundary/Interior Sensors ($x_u, y_u$) vs. Collocation Targets ($x_f, y_f$)}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}The Illusion of ``Loss'' in B-PINNs: Energy Equivalence}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Boundary vs. Physics Competition: Trivial Solutions and Posterior Collapse}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Standard PINNs: Optimizer Laziness and Trivial Minima}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Bayesian PINNs: Energy Wells and Posterior Collapse}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}HMC and Autograd Graph Detachment in PyTorch}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Why the Leapfrog Integrator requires \texttt  {torch.no\_grad()}}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Why Potential Energy $U(\theta )$ requires Autograd tracking}{3}{}\protected@file@percent }
\gdef \@abspage@last{3}
